{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report: act_report\n",
    "* Create a **250-word-minimum written report** called \"act_report.pdf\" or \"act_report.html\" that communicates the insights and displays the visualization(s) produced from your wrangled data. This is to be framed as an external document, like a blog post or magazine article, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The twitter archive master.csv file was produced by cleaning and concatenating the three datasets of theÂ Twitter WeRateDogs data. A few conclusions drawn from the dataset are as follows:\n",
    "Do dog tweets with high rating numerators have a higher level of confidence?\n",
    "Which Twitter handle was the most used in 2015?\n",
    "How much has test level performance improved between 2015 and 2017?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Do dog tweets with high rating_numerator gain good conf_level?\n",
    "For this analysis, two columns (conf level and rating numerator) were compared: The objective \n",
    "is to see the relationship between rating numerator and conf level. This was \n",
    "gotten by calculating the median of the conf level melted into low and high groups. The \n",
    "outcome of the bin category was compared to the rating numerator mean. Figure 1 clearly \n",
    "demonstrates a considerable difference between Low and High conf level evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: The most popular twitter account name 2015?\n",
    "This analysis assesses the participation of Twitter account owners in WeRateDogs' tweets. A \n",
    "drill-down of 2015 records, sorting Twitter account names and arranging their involvement \n",
    "according to total tweet count. Figure 2 is a bar chart illustrating the general participation of all \n",
    "2015-identified accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3: How much has test_level performance from 2015 - 2017?\n",
    "This analysis tries to provide a summary of the algorithm's performance from \n",
    "2015 to 2017. As shown in Figure 3, this examination was performed by obtaining and \n",
    "visualizing the mean difference between the two years in question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
